# Example configuration for discord-stt bot
# Copy this file to bot.toml and edit values as needed

# Discord bot configuration
[discord]
# List of (numeric) user IDs allowed to use commands
allowed_commanders = []

# Whisper model configuration
[whisper]
# Model name for speech-to-text
model = "openai/whisper-small.en"
# Log probability threshold for Whisper transcription (lower = more speculative)
logprob_threshold = -1.0
# No speech threshold for Whisper (0.0-1.0, lower = more strict about detecting speech)
no_speech_threshold = 0.1
# Initial prompt for Whisper to condition the transcription. You can add a few proper nouns here as hints.
prompt = "Dungeons and Dragons, spell, roll, saving throw, initiative, owlbear, dndbeyond, discord."

# Voice handling configuration
[voice]
# Seconds of silence before ending a segment
silence_threshold_seconds = 1.25
# Voice Activity Detection (VAD) threshold for Silero VAD (0.0-1.0, higher = more strict)
vad_threshold = 0.75
# Maximum allowed speech buffer length in seconds before forced into processing (0 = disabled)
max_speech_buf_seconds = 60

# Configuration for generating outlines.
[wrapup]
# OpenAI model name
model = "gpt-4o-mini"
# List of tips for the wrapup LLM.
tips = []

# Mapping of usernames to character names
[wrapup.username_map]

# Mapping of phrases to remap in the chat log.
[wrapup.phrase_map]

# Configuration for the transcript refiner using Ollama
[refiner]
# The name of the Ollama model to use for refining transcripts (e.g., "llama3", "mistral")
model = "llama3"
# The number of previous log entries to provide as context to the refiner model
context_log_lines = 10
